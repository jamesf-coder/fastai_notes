{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.AI\n",
    "Notes and example code on using fast.ai.\n",
    "\n",
    "Best place to find information is in the docs!\n",
    "https://docs.fast.ai/\n",
    "\n",
    "FastAI can deal with:\n",
    "- images\n",
    "- text\n",
    "- tabular data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.text.all import *\n",
    "from fastai.tabular.all import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat/Dog example\n",
    "\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "# Callback to deal with the incoming pictures of cats and dogs\n",
    "# Files that start with an upper-case letter are pictures of cats\n",
    "def is_cat(x): \n",
    "    return x[0].isupper()\n",
    "\n",
    "# Dataloader - important bit is the valid_pct - which tells fastai to hold 20% for validation (not included in training)\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "# Create CNN using resnet34 model\n",
    "# The 34 in resnet34 refers to the number of layers in this variant of the architecture (other options are 18, 50, 101, and 152). \n",
    "# A metric is a function that measures the quality of the model's predictions using the validation set, and will be printed at \n",
    "# the end of each epoch. In this case, we're using error_rate, which is a function provided by fastai that does just what it \n",
    "# says: tells you what percentage of images in the validation set are being classified incorrectly. Another common metric for \n",
    "# classification is accuracy (which is just 1.0 - error_rate). fastai provides many more,\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "\n",
    "# Fine tune using the dataloader object\n",
    "learn.fine_tune(1)\n",
    "\n",
    "# Supply image to test with\n",
    "uploader = SimpleNamespace(data = ['images/chapter1_cat_example.jpg'])\n",
    "\n",
    "img = PILImage.create(uploader.data[0])\n",
    "is_cat,_,probs = learn.predict(img)\n",
    "print(f\"Is this a cat?: {is_cat}.\")\n",
    "print(f\"Probability it's a cat: {probs[1].item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune the AWD_LSTM model on IMDB data to be able to calculate setiment of a string.\n",
    "# Struggle to run this one locally due to running out of VRAM.  Reduce the bs (batchsize) below.\n",
    "\n",
    "# grab the IMDB data\n",
    "# bs is the batch-size - which can be reduced to 8, 4, etc to reduce memory usage during training\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=32)\n",
    "# create the AWS_LSTM model\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "# fine tune\n",
    "learn.fine_tune(4, 1e-2)\n",
    "\n",
    "# example useage:\n",
    "learn.predict(\"I really liked that movie!\")\n",
    "# -> ('neg', tensor(0), tensor([0.8786, 0.1214]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/secondary/hack/fastbook-course/.venv/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.380413</td>\n",
       "      <td>0.382440</td>\n",
       "      <td>0.818489</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.361306</td>\n",
       "      <td>0.360611</td>\n",
       "      <td>0.828931</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.349509</td>\n",
       "      <td>0.358183</td>\n",
       "      <td>0.830006</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105563</td>\n",
       "      <td>1.080978</td>\n",
       "      <td>-0.032015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.114287</td>\n",
       "      <td>0.053980</td>\n",
       "      <td>-0.422627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.691827</td>\n",
       "      <td>1.196191</td>\n",
       "      <td>-2.766299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.041004</td>\n",
       "      <td>1.512582</td>\n",
       "      <td>1.921046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.066966</td>\n",
       "      <td>-1.508145</td>\n",
       "      <td>-0.422627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.993683</td>\n",
       "      <td>0.800836</td>\n",
       "      <td>-0.422627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.545261</td>\n",
       "      <td>0.703742</td>\n",
       "      <td>-0.422627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.041004</td>\n",
       "      <td>-1.112305</td>\n",
       "      <td>-0.422627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.765110</td>\n",
       "      <td>-0.527510</td>\n",
       "      <td>2.311658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tabular data example\n",
    "\n",
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "\n",
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                'relationship', 'race'],\n",
    "cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "procs = [Categorify, FillMissing, Normalize])\n",
    "\n",
    "learn = tabular_learner(dls, metrics=accuracy)    \n",
    "\n",
    "# there's no pretrained model for tabular data that we finetune, so we train from-scratch\n",
    "# run 3 epochs\n",
    "learn.fit_one_cycle(3)\n",
    "\n",
    "# use this to show the model\n",
    "learn.show_results()\n",
    "\n",
    "# TODO: need to figure out how to run .predict() against this model...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters are parameters that are set prior to the training process and remain constant during training. These parameters control the behavior of the algorithm and influence the performance of the model. Unlike model parameters, which are learned during the training process (such as weights in neural networks), hyperparameters are set by the practitioner or determined through techniques like hyperparameter tuning.\n",
    "\n",
    "Here are some common hyperparameters in deep learning:\n",
    "\n",
    "1. Learning Rate: This hyperparameter controls the step size during the optimization process. A higher learning rate can lead to faster convergence but may overshoot the optimal solution, while a lower learning rate may converge slowly.\n",
    "\n",
    "2. Batch Size: It determines the number of samples that are propagated through the network at once. Larger batch sizes can lead to faster training but require more memory, while smaller batch sizes may lead to slower convergence but can provide a more accurate estimate of the gradient.\n",
    "\n",
    "3. Number of Epochs: An epoch is one complete pass through the entire training dataset. The number of epochs is a hyperparameter that specifies how many times the learning algorithm will work through the entire training dataset.\n",
    "\n",
    "4. Network Architecture: Hyperparameters related to the architecture of the neural network, such as the number of layers, the number of neurons in each layer, types of activation functions, etc.\n",
    "\n",
    "5. Regularization Parameters: Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. Hyperparameters such as L1 or L2 regularization strength are examples.\n",
    "\n",
    "6. Dropout Rate: Dropout is a regularization technique where randomly selected neurons are ignored during training. The dropout rate is the probability that a neuron will be dropped out during training.\n",
    "\n",
    "7. Optimizer Parameters: Hyperparameters related to the optimization algorithm used during training, such as momentum, decay rates, etc.\n",
    "\n",
    "8. Activation Functions: Hyperparameters related to the choice of activation functions used in the hidden layers of a neural network, such as ReLU, sigmoid, tanh, etc.\n",
    "\n",
    "Choosing appropriate hyperparameters is crucial for achieving good performance and generalization of the model. Hyperparameter tuning, often done through techniques like grid search or random search, involves experimenting with different combinations of hyperparameters to find the set that yields the best performance on a validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
